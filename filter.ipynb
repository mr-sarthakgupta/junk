{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eldern', 'elders', 'welder']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the words from the file\n",
    "with open(\"words_250000_train.txt\", \"r\") as file:\n",
    "    words = file.read().splitlines()\n",
    "\n",
    "# Find words containing 'elder', not containing 'k', 'i', or 'a', and having a length of 6\n",
    "filtered_words = [word for word in words if 'elder' in word and all(ch not in word for ch in 'kia') and len(word) == 6]\n",
    "\n",
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Shuffle the words\n",
    "random.shuffle(words)\n",
    "\n",
    "# Split the words into training and validation sets\n",
    "training_words = words[:200000]\n",
    "validation_words = words[200000:]\n",
    "\n",
    "# Save the training words to a new file\n",
    "with open(\"words_200000_train.txt\", \"w\") as train_file:\n",
    "    for word in training_words:\n",
    "        train_file.write(word + \"\\n\")\n",
    "\n",
    "# Save the validation words to a new file\n",
    "with open(\"words_50000_val.txt\", \"w\") as val_file:\n",
    "    for word in validation_words:\n",
    "        val_file.write(word + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e',\n",
       " 'i',\n",
       " 'a',\n",
       " 'n',\n",
       " 'o',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'l',\n",
       " 'c',\n",
       " 'u',\n",
       " 'd',\n",
       " 'p',\n",
       " 'm',\n",
       " 'h',\n",
       " 'g',\n",
       " 'y',\n",
       " 'b',\n",
       " 'f',\n",
       " 'v',\n",
       " 'k',\n",
       " 'w',\n",
       " 'z',\n",
       " 'x',\n",
       " 'q',\n",
       " 'j']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Join all the words in the training set into a single string\n",
    "all_letters = ''.join(training_words)\n",
    "\n",
    "# Count the frequency of each letter\n",
    "letter_counts = Counter(all_letters)\n",
    "\n",
    "# Sort the letters by frequency in decreasing order\n",
    "sorted_letters_by_frequency = sorted(letter_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Extract just the letters in sorted order\n",
    "sorted_letters = [letter for letter, count in sorted_letters_by_frequency]\n",
    "\n",
    "sorted_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['er',\n",
       " 'in',\n",
       " 'ti',\n",
       " 'on',\n",
       " 'es',\n",
       " 'te',\n",
       " 'an',\n",
       " 're',\n",
       " 'at',\n",
       " 'al',\n",
       " 'en',\n",
       " 'ed',\n",
       " 'le',\n",
       " 'ri',\n",
       " 'is',\n",
       " 'ra',\n",
       " 'ic',\n",
       " 'st',\n",
       " 'ar',\n",
       " 'ne',\n",
       " 'ng',\n",
       " 'li',\n",
       " 'ro',\n",
       " 'or',\n",
       " 'nt',\n",
       " 'la',\n",
       " 'un',\n",
       " 'it',\n",
       " 'co',\n",
       " 'el',\n",
       " 'de',\n",
       " 'se',\n",
       " 'll',\n",
       " 'ni',\n",
       " 'ca',\n",
       " 'to',\n",
       " 'ta',\n",
       " 'ss',\n",
       " 'io',\n",
       " 'ma',\n",
       " 'ch',\n",
       " 'ou',\n",
       " 'ia',\n",
       " 'he',\n",
       " 'lo',\n",
       " 'tr',\n",
       " 'us',\n",
       " 'no',\n",
       " 'si',\n",
       " 'ly',\n",
       " 'me',\n",
       " 'di',\n",
       " 'na',\n",
       " 'ol',\n",
       " 'et',\n",
       " 've',\n",
       " 'il',\n",
       " 'as',\n",
       " 'ac',\n",
       " 'mi',\n",
       " 'th',\n",
       " 'ea',\n",
       " 'pe',\n",
       " 'nd',\n",
       " 'ha',\n",
       " 'om',\n",
       " 'ce',\n",
       " 'os',\n",
       " 'hi',\n",
       " 'ph',\n",
       " 'ho',\n",
       " 'ur',\n",
       " 'pr',\n",
       " 'ns',\n",
       " 'id',\n",
       " 'ie',\n",
       " 'op',\n",
       " 'ul',\n",
       " 'nc',\n",
       " 'ec',\n",
       " 'ot',\n",
       " 'sh',\n",
       " 'ge',\n",
       " 'mo',\n",
       " 'pa',\n",
       " 'em',\n",
       " 'ab',\n",
       " 'po',\n",
       " 'bl',\n",
       " 'am',\n",
       " 'rs',\n",
       " 'ci',\n",
       " 'ad',\n",
       " 'pi',\n",
       " 'oc',\n",
       " 'ap',\n",
       " 'be',\n",
       " 'su',\n",
       " 'og',\n",
       " 'sa']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Read the words from the file\n",
    "with open(\"words_train_split.txt\", \"r\") as file:\n",
    "    words_split = file.read().splitlines()\n",
    "\n",
    "# Generate bigrams from the words\n",
    "bigrams = [word[i:i+2] for word in words_split for i in range(len(word) - 1)]\n",
    "\n",
    "# Count the frequency of each bigram\n",
    "bigram_counts = Counter(bigrams)\n",
    "\n",
    "# Get the 100 most common bigrams\n",
    "most_common_bigrams = bigram_counts.most_common(100)\n",
    "\n",
    "most_common_bigrams = [bigram for bigram, count in most_common_bigrams]\n",
    "\n",
    "most_common_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ati',\n",
       " 'tio',\n",
       " 'nes',\n",
       " 'ter',\n",
       " 'ica',\n",
       " 'all',\n",
       " 'ent',\n",
       " 'tin',\n",
       " 'non',\n",
       " 'per',\n",
       " 'eri',\n",
       " 'ver',\n",
       " 'ant',\n",
       " 'ate',\n",
       " 'abl',\n",
       " 'ali',\n",
       " 'pre',\n",
       " 'tra',\n",
       " 'lin',\n",
       " 'ing',\n",
       " 'con',\n",
       " 'nte',\n",
       " 'pro',\n",
       " 'sti',\n",
       " 'ion',\n",
       " 'nti',\n",
       " 'ste',\n",
       " 'tri',\n",
       " 'rat',\n",
       " 'ell',\n",
       " 'oni',\n",
       " 'nde',\n",
       " 'ist',\n",
       " 'res',\n",
       " 'rin',\n",
       " 'the',\n",
       " 'ari',\n",
       " 'ine',\n",
       " 'ene',\n",
       " 'ill',\n",
       " 'lat',\n",
       " 'ove',\n",
       " 'iti',\n",
       " 'lit',\n",
       " 'str',\n",
       " 'ere',\n",
       " 'ran',\n",
       " 'tic',\n",
       " 'cal',\n",
       " 'int',\n",
       " 'men',\n",
       " 'era',\n",
       " 'gra',\n",
       " 'ili',\n",
       " 'min',\n",
       " 'dis',\n",
       " 'olo',\n",
       " 'ast',\n",
       " 'ona',\n",
       " 'tro',\n",
       " 'est',\n",
       " 'ani',\n",
       " 'mat',\n",
       " 'chi',\n",
       " 'ero',\n",
       " 'sta',\n",
       " 'der',\n",
       " 'ato',\n",
       " 'and',\n",
       " 'tiv',\n",
       " 'oph',\n",
       " 'ect',\n",
       " 'her',\n",
       " 'che',\n",
       " 'und',\n",
       " 'ina',\n",
       " 'tor',\n",
       " 'for',\n",
       " 'nat',\n",
       " 'log',\n",
       " 'rea',\n",
       " 'pho',\n",
       " 'cti',\n",
       " 'ess',\n",
       " 'ori',\n",
       " 'emi',\n",
       " 'nis',\n",
       " 'cat',\n",
       " 'lli',\n",
       " 'cha',\n",
       " 'sto',\n",
       " 'ous',\n",
       " 'lis',\n",
       " 'rop',\n",
       " 'ula',\n",
       " 'par',\n",
       " 'ele',\n",
       " 'eli',\n",
       " 'les',\n",
       " 'ers']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"words_train_split.txt\", \"r\") as file:\n",
    "    words_split = file.read().splitlines()\n",
    "\n",
    "# Generate bigrams from the words\n",
    "trigrams = [word[i:i+3] for word in words_split for i in range(len(word) - 3)]\n",
    "\n",
    "# Count the frequency of each bigram\n",
    "trigram_counts = Counter(trigrams)\n",
    "\n",
    "# Get the 100 most common bigrams\n",
    "most_common_trigrams = trigram_counts.most_common(100)\n",
    "\n",
    "most_common_trigrams = [trigram for trigram, count in most_common_trigrams]\n",
    "\n",
    "most_common_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['atio',\n",
       " 'over',\n",
       " 'tion',\n",
       " 'nter',\n",
       " 'ical',\n",
       " 'enes',\n",
       " 'inte',\n",
       " 'call',\n",
       " 'olog',\n",
       " 'anti',\n",
       " 'tica',\n",
       " 'atin',\n",
       " 'unde',\n",
       " 'nder',\n",
       " 'rati',\n",
       " 'logi',\n",
       " 'ingl',\n",
       " 'grap',\n",
       " 'iona',\n",
       " 'ogra',\n",
       " 'ilit',\n",
       " 'isti',\n",
       " 'ther',\n",
       " 'bili',\n",
       " 'alis',\n",
       " 'ativ',\n",
       " 'enti',\n",
       " 'uper',\n",
       " 'ster',\n",
       " 'icat',\n",
       " 'lati',\n",
       " 'mati',\n",
       " 'teri',\n",
       " 'raph',\n",
       " 'supe',\n",
       " 'ment',\n",
       " 'ines',\n",
       " 'erin',\n",
       " 'ulat',\n",
       " 'stra',\n",
       " 'enta',\n",
       " 'erat',\n",
       " 'self',\n",
       " 'tati',\n",
       " 'esse',\n",
       " 'semi',\n",
       " 'snes',\n",
       " 'ight',\n",
       " 'dnes',\n",
       " 'peri',\n",
       " 'inat',\n",
       " 'pres',\n",
       " 'tran',\n",
       " 'aliz',\n",
       " 'cula',\n",
       " 'stic',\n",
       " 'tric',\n",
       " 'comp',\n",
       " 'omet',\n",
       " 'tive',\n",
       " 'ctio',\n",
       " 'vill',\n",
       " 'well',\n",
       " 'lene',\n",
       " 'tabl',\n",
       " 'ator',\n",
       " 'ecti',\n",
       " 'abil',\n",
       " 'cati',\n",
       " 'ousl',\n",
       " 'blen',\n",
       " 'nati',\n",
       " 'emen',\n",
       " 'opho',\n",
       " 'acti',\n",
       " 'able',\n",
       " 'para',\n",
       " 'lect',\n",
       " 'edne',\n",
       " 'vers',\n",
       " 'izat',\n",
       " 'cont',\n",
       " 'cons',\n",
       " 'zati',\n",
       " 'usne',\n",
       " 'asti',\n",
       " 'ousn',\n",
       " 'tero',\n",
       " 'izin',\n",
       " 'onis',\n",
       " 'anth',\n",
       " 'late',\n",
       " 'ogen',\n",
       " 'anis',\n",
       " 'rica',\n",
       " 'othe',\n",
       " 'trop',\n",
       " 'reco',\n",
       " 'elli',\n",
       " 'arch']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"words_train_split.txt\", \"r\") as file:\n",
    "    words_split = file.read().splitlines()\n",
    "\n",
    "# Generate bigrams from the words\n",
    "qgrams = [word[i:i+4] for word in words_split for i in range(len(word) - 4)]\n",
    "\n",
    "# Count the frequency of each bigram\n",
    "qgram_counts = Counter(qgrams)\n",
    "\n",
    "# Get the 100 most common bigrams\n",
    "most_common_qgrams = qgram_counts.most_common(100)\n",
    "\n",
    "most_common_qgrams = [qgram for qgram, count in most_common_qgrams]\n",
    "\n",
    "most_common_qgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeding Letter Co-Frequency Matrix:\n",
      "    a b c d e f g h i j k l m n o p q r s t u v w x y z\n",
      "a 245 6427 9223 5372 2945 1237 4341 967 3988 184 1780 20657 6109 22111 231 5305 179 17455 9332 20775 3041 2142 1177 665 1668 849 \n",
      "b 4760 934 194 226 5234  75  42 117 4464 135  19 6272 134  97 4006 108   4 3588 777 246 2642  65  48   3 422   6 \n",
      "c 11438  22 1263  57 7951  29  30 10543 5644   1 4011 2801  72 130 12436  43 103 4245 528 4936 3876  15  20   2 1685  32 \n",
      "d 4775 327 235 1164 12292 286 644 345 9681 156  37 1701 404 832 4562 173   7 2795 1558 184 1919 244 353   3 1019  35 \n",
      "e 8994 1910 6777 20338 4797 2062 2321 877 2479 228 517 12415 6434 20513 2618 4481 457 34364 23921 9465 2285 2084 1461 2552 1390 281 \n",
      "f 2294  80 172 134 2934 1823  39  55 3906  17  17 2173  77  33 3122  97   5 1775 312 811 2022  16  61   3 439   3 \n",
      "g 4121 157  56 107 6483  88 1150 2101 4190  19  30 2946 429 1385 2664  72   2 3925 902 190 2072  15 155   1 971   8 \n",
      "h 8444 235 129 104 10268 172  62  96 7901  13  52 933 524 551 7810 128  11 2203 522 1647 1702  32 260   1 3791   8 \n",
      "i 10300 2399 17757 7303 7294 3090 3998 242 366  94 1346 9341 4316 33351 10662 3611 248 4280 18003 12502 1165 4165  82 457  68 3958 \n",
      "j 871   2  10   6 657   3   2   5 235   6   8   4   3  13 661   1   0   4   9   2 792   1   2   0   8   0 \n",
      "k 1564 182  71  53 4536 143  30 312 2712  22  80 731 140 479 731  99   3 274 942 176 345  38 183   0 400   2 \n",
      "l 13424 569 815 1886 19502 1611 485 193 16828  29 539 11881 853 574 10198 838  16 175 1769 2032 3424 702 232   7 9707  38 \n",
      "m 10566 2301 199  88 9703 139  38  55 9114  17  25 232 1776 513 6452 3476   5 108 1046  87 2053  55  62   4 1343   8 \n",
      "n 9656 842 6790 8611 17262 1676 16936 786 11452 282 1290 942 791 2449 9951 1216 239 1030 7369 14972 1687 972 510  50 972 316 \n",
      "o 2051 2431 5345 4081 1524 1391 4989 613 2946 106 1154 9512 8278 24129 4478 7174 176 15468 7943 6763 10348 3396 3087 991 617 401 \n",
      "p 6447 128 104  81 8929 107  51 7838 5357  10  43 3761 133 273 6401 1972   1 7542 1958 2193 1945  15 107   2 853   1 \n",
      "q  20   1   4   2   5   2   1   1  10   0   1   4   3   2   3   1   3   4   7   4 3399   0   4   0   0   0 \n",
      "r 17961 1703 2968 3373 21813 844 1964 1054 18330 104 1153 1749 3431 2582 16466 1778  80 3153 5929 4866 3336 989 509  10 3863  87 \n",
      "s 4979 437 4865 215 12117 285 162 6526 9742  44 1131 2041 3668 1313 4811 4507 523 185 10689 17752 5193 271 860   5 1509  31 \n",
      "t 10861 378 1097 154 23080 477 184 9075 24386  47  56 1882 522 422 11093 269  15 10143 3062 3710 3722  83 1070   4 3633 282 \n",
      "u 2568 2708 2343 1965 1993 540 1465  65 2226  57 330 7035 4376 13306 522 2566  25 7741 9952 4861  36 235  24 223  84 172 \n",
      "v 2724   2  10  11 9372   4   8   3 4358   1  13  32  13  15 1383   7   0  75  50  11 211  23   3   1 104   2 \n",
      "w 2898 163  91 151 2814  98  34 934 2727   4 100 336 103 867 2228  65   1 461 417 119  72  11  70   0 133  10 \n",
      "x 518  31 304  13 562  35   8 102 1073   3   2  52  25  11 367 471   6  14  63 602 140   2  23   7 357   1 \n",
      "y 1208 358 1156 764 1227 233 464 166 758  14  65 1952 1195 1269 890 1805   6 994 1882 1139 137  77 218  95  21 104 \n",
      "z 1272  20  10  10 3096   4   8  21 1203   1  16 133  23  14 913  12   2  13  20  17  94   6  12   0 239 317 \n",
      "\n",
      "\n",
      "Preceding Letter Co-Frequency Matrix:\n",
      "    a b c d e f g h i j k l m n o p q r s t u v w x y z\n",
      "a 245 4760 11438 4775 8994 2294 4121 8444 10300 871 1564 13424 10566 9656 2051 6447  20 17961 4979 10861 2568 2724 2898 518 1208 1272 \n",
      "b 6427 934  22 327 1910  80 157 235 2399   2 182 569 2301 842 2431 128   1 1703 437 378 2708   2 163  31 358  20 \n",
      "c 9223 194 1263 235 6777 172  56 129 17757  10  71 815 199 6790 5345 104   4 2968 4865 1097 2343  10  91 304 1156  10 \n",
      "d 5372 226  57 1164 20338 134 107 104 7303   6  53 1886  88 8611 4081  81   2 3373 215 154 1965  11 151  13 764  10 \n",
      "e 2945 5234 7951 12292 4797 2934 6483 10268 7294 657 4536 19502 9703 17262 1524 8929   5 21813 12117 23080 1993 9372 2814 562 1227 3096 \n",
      "f 1237  75  29 286 2062 1823  88 172 3090   3 143 1611 139 1676 1391 107   2 844 285 477 540   4  98  35 233   4 \n",
      "g 4341  42  30 644 2321  39 1150  62 3998   2  30 485  38 16936 4989  51   1 1964 162 184 1465   8  34   8 464   8 \n",
      "h 967 117 10543 345 877  55 2101  96 242   5 312 193  55 786 613 7838   1 1054 6526 9075  65   3 934 102 166  21 \n",
      "i 3988 4464 5644 9681 2479 3906 4190 7901 366 235 2712 16828 9114 11452 2946 5357  10 18330 9742 24386 2226 4358 2727 1073 758 1203 \n",
      "j 184 135   1 156 228  17  19  13  94   6  22  29  17 282 106  10   0 104  44  47  57   1   4   3  14   1 \n",
      "k 1780  19 4011  37 517  17  30  52 1346   8  80 539  25 1290 1154  43   1 1153 1131  56 330  13 100   2  65  16 \n",
      "l 20657 6272 2801 1701 12415 2173 2946 933 9341   4 731 11881 232 942 9512 3761   4 1749 2041 1882 7035  32 336  52 1952 133 \n",
      "m 6109 134  72 404 6434  77 429 524 4316   3 140 853 1776 791 8278 133   3 3431 3668 522 4376  13 103  25 1195  23 \n",
      "n 22111  97 130 832 20513  33 1385 551 33351  13 479 574 513 2449 24129 273   2 2582 1313 422 13306  15 867  11 1269  14 \n",
      "o 231 4006 12436 4562 2618 3122 2664 7810 10662 661 731 10198 6452 9951 4478 6401   3 16466 4811 11093 522 1383 2228 367 890 913 \n",
      "p 5305 108  43 173 4481  97  72 128 3611   1  99 838 3476 1216 7174 1972   1 1778 4507 269 2566   7  65 471 1805  12 \n",
      "q 179   4 103   7 457   5   2  11 248   0   3  16   5 239 176   1   3  80 523  15  25   0   1   6   6   2 \n",
      "r 17455 3588 4245 2795 34364 1775 3925 2203 4280   4 274 175 108 1030 15468 7542   4 3153 185 10143 7741  75 461  14 994  13 \n",
      "s 9332 777 528 1558 23921 312 902 522 18003   9 942 1769 1046 7369 7943 1958   7 5929 10689 3062 9952  50 417  63 1882  20 \n",
      "t 20775 246 4936 184 9465 811 190 1647 12502   2 176 2032  87 14972 6763 2193   4 4866 17752 3710 4861  11 119 602 1139  17 \n",
      "u 3041 2642 3876 1919 2285 2022 2072 1702 1165 792 345 3424 2053 1687 10348 1945 3399 3336 5193 3722  36 211  72 140 137  94 \n",
      "v 2142  65  15 244 2084  16  15  32 4165   1  38 702  55 972 3396  15   0 989 271  83 235  23  11   2  77   6 \n",
      "w 1177  48  20 353 1461  61 155 260  82   2 183 232  62 510 3087 107   4 509 860 1070  24   3  70  23 218  12 \n",
      "x 665   3   2   3 2552   3   1   1 457   0   0   7   4  50 991   2   0  10   5   4 223   1   0   7  95   0 \n",
      "y 1668 422 1685 1019 1390 439 971 3791  68   8 400 9707 1343 972 617 853   0 3863 1509 3633  84 104 133 357  21 239 \n",
      "z 849   6  32  35 281   3   8   8 3958   0   2  38   8 316 401   1   0  87  31 282 172   2  10   1 104 317 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "\n",
    "def generate_letter_cofrequency_matrices(words):\n",
    "    \"\"\"\n",
    "    Generate co-frequency matrices for letters that succeed and precede each other.\n",
    "    \n",
    "    Parameters:\n",
    "    words (list): List of words to analyze\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (succeeding_matrix, preceding_matrix)\n",
    "    \"\"\"\n",
    "    # Create lowercase alphabet for matrix indexing\n",
    "    alphabet = string.ascii_lowercase\n",
    "    \n",
    "    # Initialize matrices with zeros\n",
    "    succeeding_matrix = np.zeros((26, 26), dtype=int)\n",
    "    preceding_matrix = np.zeros((26, 26), dtype=int)\n",
    "    \n",
    "    # Process each word\n",
    "    for word in words:\n",
    "        # Convert to lowercase\n",
    "        word = word.lower()\n",
    "        \n",
    "        # Analyze letter successions\n",
    "        for i in range(len(word) - 1):\n",
    "            # Current and next letter\n",
    "            current_letter = word[i]\n",
    "            next_letter = word[i + 1]\n",
    "            \n",
    "            # Skip if either letter is not in alphabet\n",
    "            if current_letter not in alphabet or next_letter not in alphabet:\n",
    "                continue\n",
    "            \n",
    "            # Get matrix indices\n",
    "            current_idx = alphabet.index(current_letter)\n",
    "            next_idx = alphabet.index(next_letter)\n",
    "            \n",
    "            # Increment succeeding matrix\n",
    "            succeeding_matrix[current_idx, next_idx] += 1\n",
    "        \n",
    "        # Analyze letter precedences\n",
    "        for i in range(1, len(word)):\n",
    "            # Current and previous letter\n",
    "            current_letter = word[i]\n",
    "            prev_letter = word[i - 1]\n",
    "            \n",
    "            # Skip if either letter is not in alphabet\n",
    "            if current_letter not in alphabet or prev_letter not in alphabet:\n",
    "                continue\n",
    "            \n",
    "            # Get matrix indices\n",
    "            current_idx = alphabet.index(current_letter)\n",
    "            prev_idx = alphabet.index(prev_letter)\n",
    "            \n",
    "            # Increment preceding matrix\n",
    "            preceding_matrix[current_idx, prev_idx] += 1\n",
    "    \n",
    "    return succeeding_matrix, preceding_matrix\n",
    "\n",
    "def print_matrix(matrix, matrix_type):\n",
    "    \"\"\"\n",
    "    Pretty print the co-frequency matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    matrix (numpy.ndarray): The co-frequency matrix\n",
    "    matrix_type (str): 'Succeeding' or 'Preceding'\n",
    "    \"\"\"\n",
    "    alphabet = string.ascii_lowercase\n",
    "    \n",
    "    print(f\"{matrix_type} Letter Co-Frequency Matrix:\")\n",
    "    print(\"    \" + \" \".join(alphabet))\n",
    "    \n",
    "    for i, row in enumerate(matrix):\n",
    "        print(f\"{alphabet[i]} \", end=\"\")\n",
    "        for val in row:\n",
    "            print(f\"{val:3}\", end=\" \")\n",
    "        print()\n",
    "\n",
    "# Example usage\n",
    "def example_usage():\n",
    "    # Sample word list\n",
    "    words = [\n",
    "        \"hello\", \"world\", \"python\", \"programming\", \"computer\", \n",
    "        \"science\", \"algorithm\", \"machine\", \"learning\", \"data\"\n",
    "    ]\n",
    "    \n",
    "    # Generate matrices\n",
    "    succeeding_matrix, preceding_matrix = generate_letter_cofrequency_matrices(words)\n",
    "    \n",
    "    # Print matrices\n",
    "    print_matrix(succeeding_matrix, \"Succeeding\")\n",
    "    print(\"\\n\")\n",
    "    print_matrix(preceding_matrix, \"Preceding\")\n",
    "\n",
    "# Uncomment to run example\n",
    "# example_usage()import numpy as np\n",
    "import string\n",
    "\n",
    "def generate_letter_cofrequency_matrices(words):\n",
    "    \"\"\"\n",
    "    Generate co-frequency matrices for letters that succeed and precede each other.\n",
    "    \n",
    "    Parameters:\n",
    "    words (list): List of words to analyze\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (succeeding_matrix, preceding_matrix)\n",
    "    \"\"\"\n",
    "    # Create lowercase alphabet for matrix indexing\n",
    "    alphabet = string.ascii_lowercase\n",
    "    \n",
    "    # Initialize matrices with zeros\n",
    "    succeeding_matrix = np.zeros((26, 26), dtype=int)\n",
    "    preceding_matrix = np.zeros((26, 26), dtype=int)\n",
    "    \n",
    "    # Process each word\n",
    "    for word in words:\n",
    "        # Convert to lowercase\n",
    "        word = word.lower()\n",
    "        \n",
    "        # Analyze letter successions\n",
    "        for i in range(len(word) - 1):\n",
    "            # Current and next letter\n",
    "            current_letter = word[i]\n",
    "            next_letter = word[i + 1]\n",
    "            \n",
    "            # Skip if either letter is not in alphabet\n",
    "            if current_letter not in alphabet or next_letter not in alphabet:\n",
    "                continue\n",
    "            \n",
    "            # Get matrix indices\n",
    "            current_idx = alphabet.index(current_letter)\n",
    "            next_idx = alphabet.index(next_letter)\n",
    "            \n",
    "            # Increment succeeding matrix\n",
    "            succeeding_matrix[current_idx, next_idx] += 1\n",
    "        \n",
    "        # Analyze letter precedences\n",
    "        for i in range(1, len(word)):\n",
    "            # Current and previous letter\n",
    "            current_letter = word[i]\n",
    "            prev_letter = word[i - 1]\n",
    "            \n",
    "            # Skip if either letter is not in alphabet\n",
    "            if current_letter not in alphabet or prev_letter not in alphabet:\n",
    "                continue\n",
    "            \n",
    "            # Get matrix indices\n",
    "            current_idx = alphabet.index(current_letter)\n",
    "            prev_idx = alphabet.index(prev_letter)\n",
    "            \n",
    "            # Increment preceding matrix\n",
    "            preceding_matrix[current_idx, prev_idx] += 1\n",
    "    \n",
    "    return succeeding_matrix, preceding_matrix\n",
    "\n",
    "def print_matrix(matrix, matrix_type):\n",
    "    \"\"\"\n",
    "    Pretty print the co-frequency matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    matrix (numpy.ndarray): The co-frequency matrix\n",
    "    matrix_type (str): 'Succeeding' or 'Preceding'\n",
    "    \"\"\"\n",
    "    alphabet = string.ascii_lowercase\n",
    "    \n",
    "    print(f\"{matrix_type} Letter Co-Frequency Matrix:\")\n",
    "    print(\"    \" + \" \".join(alphabet))\n",
    "    \n",
    "    for i, row in enumerate(matrix):\n",
    "        print(f\"{alphabet[i]} \", end=\"\")\n",
    "        for val in row:\n",
    "            print(f\"{val:3}\", end=\" \")\n",
    "        print()\n",
    "\n",
    "# Example usage\n",
    "def example_usage():\n",
    "    # Sample word list\n",
    "    with open(\"words_train_split.txt\", \"r\") as file:\n",
    "        words = file.read().splitlines()\n",
    "    \n",
    "    # Generate matrices\n",
    "    succeeding_matrix, preceding_matrix = generate_letter_cofrequency_matrices(words)\n",
    "    \n",
    "    # Print matrices\n",
    "    print_matrix(succeeding_matrix, \"Succeeding\")\n",
    "    print(\"\\n\")\n",
    "    print_matrix(preceding_matrix, \"Preceding\")\n",
    "\n",
    "# Uncomment to run example\n",
    "example_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "\n",
    "def generate_letter_cofrequency_matrices(words):\n",
    "    \"\"\"\n",
    "    Generate co-frequency matrices for letters that succeed and precede each other.\n",
    "    \n",
    "    Parameters:\n",
    "    words (list): List of words to analyze\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (succeeding_matrix, preceding_matrix)\n",
    "    \"\"\"\n",
    "    # Create lowercase alphabet for matrix indexing\n",
    "    alphabet = string.ascii_lowercase\n",
    "    \n",
    "    # Initialize matrices with zeros\n",
    "    succeeding_matrix = np.zeros((26, 26), dtype=int)\n",
    "    preceding_matrix = np.zeros((26, 26), dtype=int)\n",
    "    \n",
    "    # Process each word\n",
    "    for word in words:\n",
    "        # Convert to lowercase\n",
    "        word = word.lower()\n",
    "        \n",
    "        # Analyze letter successions\n",
    "        for i in range(len(word) - 1):\n",
    "            # Current and next letter\n",
    "            current_letter = word[i]\n",
    "            next_letter = word[i + 1]\n",
    "            \n",
    "            # Skip if either letter is not in alphabet\n",
    "            if current_letter not in alphabet or next_letter not in alphabet:\n",
    "                continue\n",
    "            \n",
    "            # Get matrix indices\n",
    "            current_idx = alphabet.index(current_letter)\n",
    "            next_idx = alphabet.index(next_letter)\n",
    "            \n",
    "            # Increment succeeding matrix\n",
    "            succeeding_matrix[current_idx, next_idx] += 1\n",
    "        \n",
    "        # Analyze letter precedences\n",
    "        for i in range(1, len(word)):\n",
    "            # Current and previous letter\n",
    "            current_letter = word[i]\n",
    "            prev_letter = word[i - 1]\n",
    "            \n",
    "            # Skip if either letter is not in alphabet\n",
    "            if current_letter not in alphabet or prev_letter not in alphabet:\n",
    "                continue\n",
    "            \n",
    "            # Get matrix indices\n",
    "            current_idx = alphabet.index(current_letter)\n",
    "            prev_idx = alphabet.index(prev_letter)\n",
    "            \n",
    "            # Increment preceding matrix\n",
    "            preceding_matrix[current_idx, prev_idx] += 1\n",
    "    \n",
    "    return succeeding_matrix, preceding_matrix\n",
    "\n",
    "def guess(word, guessed_letters, succeeding_matrix, preceding_matrix):\n",
    "    # Predefined frequency lists\n",
    "    letters_by_frequency = [\n",
    "        'e', 't', 'a', 'o', 'i', 'n', 's', 'h', 'r', 'd',\n",
    "        'l', 'u', 'c', 'm', 'f', 'w', 'g', 'y', 'p', 'b',\n",
    "        'v', 'k', 'x', 'j', 'q', 'z'\n",
    "    ]\n",
    "    \n",
    "    bigrams_by_frequency = [\n",
    "        'th', 'he', 'in', 'er', 'an', 're', 'nd', 'on', 'en', 'at',\n",
    "        'ou', 'ed', 'ha', 'to', 'or', 'it', 'is', 'hi', 'es', 'ng'\n",
    "    ]\n",
    "    \n",
    "    trigrams_by_frequency = [\n",
    "        'the', 'and', 'ing', 'her', 'hat', 'his', 'tha', 'ere', 'for', 'ent',\n",
    "        'ion', 'ter', 'was', 'you', 'ith', 'ver', 'all', 'wit', 'thi', 'tio'\n",
    "    ]\n",
    "    \n",
    "    quadgrams_by_frequency = [\n",
    "        'that', 'ther', 'with', 'tion', 'here', 'ould', 'ight', 'have', 'hich', 'whic',\n",
    "        'this', 'thin', 'they', 'atio', 'ever', 'from', 'ough', 'were', 'hing', 'ment'\n",
    "    ]\n",
    "    \n",
    "    # Clean the word, stripping spaces and replacing \"_\" with placeholders\n",
    "    clean_word = word[::2].replace(\"_\", \".\")\n",
    "    \n",
    "    # Find length of word\n",
    "    len_word = len(clean_word)\n",
    "    \n",
    "    # Score mechanism for letter selection\n",
    "    letter_scores = {}\n",
    "    alphabet = string.ascii_lowercase\n",
    "    \n",
    "    # 1. Single Letter Frequency - Initial Base Score\n",
    "    for letter in letters_by_frequency:\n",
    "        if letter not in guessed_letters:\n",
    "            letter_scores[letter] = 1 / (letters_by_frequency.index(letter) + 1)\n",
    "    \n",
    "    # 2. Co-Frequency Matrix Scoring\n",
    "    # Find positions of known letters in the word\n",
    "    known_letter_positions = [i for i, char in enumerate(clean_word) if char != '.']\n",
    "    \n",
    "    for letter in alphabet:\n",
    "        if letter in guessed_letters:\n",
    "            continue\n",
    "        \n",
    "        # Score based on succeeding and preceding letter frequencies\n",
    "        succeeding_score = 0\n",
    "        preceding_score = 0\n",
    "        \n",
    "        # Check succeeding letter frequency\n",
    "        for pos in known_letter_positions:\n",
    "            if pos < len_word - 1 and clean_word[pos+1] == '.':\n",
    "                known_letter_idx = alphabet.index(clean_word[pos])\n",
    "                letter_idx = alphabet.index(letter)\n",
    "                succeeding_score += succeeding_matrix[known_letter_idx, letter_idx]\n",
    "        \n",
    "        # Check preceding letter frequency\n",
    "        for pos in known_letter_positions:\n",
    "            if pos > 0 and clean_word[pos-1] == '.':\n",
    "                known_letter_idx = alphabet.index(clean_word[pos])\n",
    "                letter_idx = alphabet.index(letter)\n",
    "                preceding_score += preceding_matrix[known_letter_idx, letter_idx]\n",
    "        \n",
    "        # Combine co-frequency scores with base letter frequency\n",
    "        letter_scores[letter] += (succeeding_score + preceding_score) * 0.1\n",
    "    \n",
    "    # 3. Ngram Frequency Scoring\n",
    "    # (Keep existing ngram scoring logic from previous implementation)\n",
    "    for bigram in bigrams_by_frequency:\n",
    "        if is_ngram_compatible(bigram, clean_word):\n",
    "            for letter in set(bigram):\n",
    "                if letter not in guessed_letters:\n",
    "                    letter_scores[letter] = letter_scores.get(letter, 0) + 1 / (bigrams_by_frequency.index(bigram) + 1)\n",
    "    \n",
    "    for trigram in trigrams_by_frequency:\n",
    "        if is_ngram_compatible(trigram, clean_word):\n",
    "            for letter in set(trigram):\n",
    "                if letter not in guessed_letters:\n",
    "                    letter_scores[letter] = letter_scores.get(letter, 0) + 1 / (trigrams_by_frequency.index(trigram) + 1)\n",
    "    \n",
    "    for quadgram in quadgrams_by_frequency:\n",
    "        if is_ngram_compatible(quadgram, clean_word):\n",
    "            for letter in set(quadgram):\n",
    "                if letter not in guessed_letters:\n",
    "                    letter_scores[letter] = letter_scores.get(letter, 0) + 1 / (quadgrams_by_frequency.index(quadgram) + 1)\n",
    "    \n",
    "    # If no scores found, fallback to most frequent unguessed letters\n",
    "    if not letter_scores:\n",
    "        for letter in letters_by_frequency:\n",
    "            if letter not in guessed_letters:\n",
    "                return letter\n",
    "    \n",
    "    # Select letter with highest score\n",
    "    guess_letter = max(letter_scores, key=letter_scores.get)\n",
    "    \n",
    "    return guess_letter\n",
    "\n",
    "def is_ngram_compatible(ngram, word_pattern):\n",
    "    \"\"\"\n",
    "    Check if an ngram is compatible with the current word pattern\n",
    "    \"\"\"\n",
    "    # Create a regex pattern from the ngram that respects the word pattern\n",
    "    pattern = word_pattern.replace('.', '[a-z]')\n",
    "    \n",
    "    # Check if the ngram could exist within the pattern\n",
    "    return re.search(f'(?=.{ngram}.)', pattern, re.IGNORECASE) is not None\n",
    "\n",
    "# Example usage function\n",
    "def hangman_solver_example():\n",
    "    # Sample word list for generating co-frequency matrices\n",
    "    word_list = [\n",
    "        'hello', 'world', 'python', 'programming', 'computer', \n",
    "        'science', 'algorithm', 'machine', 'learning', 'data'\n",
    "    ]\n",
    "    \n",
    "    # Generate co-frequency matrices\n",
    "    succeeding_matrix, preceding_matrix = generate_letter_cofrequency_matrices(word_list)\n",
    "    \n",
    "    # Example Hangman game scenario\n",
    "    word = \"_ _ l l _\"\n",
    "    guessed_letters = ['l']\n",
    "    \n",
    "    # Get the next letter guess\n",
    "    next_guess = guess(word, guessed_letters, succeeding_matrix, preceding_matrix)\n",
    "    \n",
    "    print(f\"Current word: {word}\")\n",
    "    print(f\"Guessed letters: {guessed_letters}\")\n",
    "    print(f\"Next guess: {next_guess}\")\n",
    "\n",
    "# Uncomment to run example\n",
    "# hangman_solver_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
